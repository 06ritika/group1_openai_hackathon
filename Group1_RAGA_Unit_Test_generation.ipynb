{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7xWlovbmZNs"
      },
      "source": [
        "**bold text** # Write comment of add unit test cases for Python program\n",
        "\n",
        "\n",
        "In this notebook, we will explore a few Python functions and a simple game implementation. We will also see how to interact with the Azure OpenAI service to assist with code-related tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AgiSlkYmZN1"
      },
      "source": [
        "*italicized text*## Creating Arthimetic pyhton function\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "The first function creates a pyhton code. Let's go through the code step by step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o6K3kUKmZN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e6f8c19-3663-448f-b990-46927aa82292"
      },
      "source": [
        "def create_calc_int_file():\n",
        "    code = \"\"\"def calculate(num1, num2, operation):\n",
        "\n",
        "    if operation == 'add':\n",
        "        return num1 + num2\n",
        "    elif operation == 'subtract':\n",
        "        return num1 - num2\n",
        "    elif operation == 'multiply':\n",
        "        return num1 * num2\n",
        "    elif operation == 'divide':\n",
        "        if num2 == 0:\n",
        "            raise ValueError(\"Cannot divide by zero.\")\n",
        "        return num1 / num2\n",
        "    else:\n",
        "        raise ValueError(\"Invalid operation. Please choose 'add', 'subtract', 'multiply', or 'divide'.\")\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    with open('calc_int.py', 'w') as file:\n",
        "        file.write(code)\n",
        "\n",
        "    print(\"Created and wrote to file: calc_int.py\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_calc_int_file()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created and wrote to file: calc_int.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX_TNmWvmZN7"
      },
      "source": [
        "## Creating a Function File\n",
        "\n",
        "Next, we create a file that contains a simple function to calculate the absolute square of the difference between two numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lNuPs5MmZN_"
      },
      "source": [
        "## Creating an Empty File\n",
        "\n",
        "We will also create an empty text file named `app2.txt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXLVxYfAmZOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2d8d57-d435-4142-9d25-43b2b36fbad1"
      },
      "source": [
        "# Creating an empty text file named app.txt\n",
        "file_name = 'app2.txt'\n",
        "\n",
        "with open(file_name, 'w') as file:\n",
        "    pass\n",
        "\n",
        "print(f\"Created file: {file_name}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created file: app2.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K-Mx8ukmZON"
      },
      "source": [
        "## Interacting with Azure OpenAI Service\n",
        "\n",
        "Finally, we will look at how to interact with the Azure OpenAI service to perform various tasks related to our code."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==1.13.3"
      ],
      "metadata": {
        "id": "rhzA2QmInOpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aadd30bc-940f-4a7d-8e87-a52844b1f30b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.13.3\n",
            "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.13.3) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.13.3)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (2.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.13.3) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (2.23.3)\n",
            "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 openai-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai import AsyncAzureOpenAI"
      ],
      "metadata": {
        "id": "2nQMKZ8znVLW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmPGJhzpmZOP"
      },
      "source": [
        "\n",
        "\n",
        "# Set to True to print the full response from OpenAI for each call\n",
        "printFullResponse = False\n",
        "\n",
        "async def main():\n",
        "  try:\n",
        "        # Get configuration settings\n",
        "        # Configuration settings\n",
        "        azure_oai_endpoint = \"https://eygroup-1.openai.azure.com/\"\n",
        "        azure_oai_key = \"ec4d26ffb81b42e7b3dd06c39805f8fb\"\n",
        "        azure_oai_deployment = \"carbrochuremodel\"\n",
        "\n",
        "        # Configure the Azure OpenAI client\n",
        "        client = AsyncAzureOpenAI(\n",
        "            azure_endpoint = azure_oai_endpoint,\n",
        "            api_key=azure_oai_key,\n",
        "            api_version=\"2024-02-15-preview\"\n",
        "        )\n",
        "\n",
        "        while True:\n",
        "            print('\\n1: Add comments to my function\\n' +\n",
        "                  '2: Write unit tests for my function\\n' +\n",
        "                  '\"quit\" to exit the program\\n')\n",
        "            command = input('Enter a number to select a task:')\n",
        "\n",
        "            if command.lower() == 'quit':\n",
        "                print('Exiting program...')\n",
        "                break\n",
        "\n",
        "            user_input = input('\\nEnter a prompt: ')\n",
        "            if command == '1' or command == '2':\n",
        "                file = open(file=\"calc_int.py\", encoding=\"utf8\").read()\n",
        "            else :\n",
        "                print(\"Invalid input. Please try again.\")\n",
        "                continue\n",
        "\n",
        "            prompt = user_input + file\n",
        "            await call_openai_model(prompt, model=azure_oai_deployment, client=client)\n",
        "\n",
        "  except Exception as ex:\n",
        "        print(ex)\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def call_openai_model(prompt, model, client):\n",
        "    # Provide a basic user message, and use the prompt content as the user message\n",
        "    system_message = \"You are a helpful AI assistant that helps programmers write code.\"\n",
        "    user_message = prompt\n",
        "\n",
        "    # Format and send the request to the model\n",
        "    messages =[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        "\n",
        "    # Call the Azure OpenAI model\n",
        "    response = await client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    # Print the response to the console, if desired\n",
        "    if printFullResponse:\n",
        "        print(response)\n",
        "\n",
        "    # Write the response to a file\n",
        "    results_file = open(file=\"app2.txt\", mode=\"w\", encoding=\"utf8\")\n",
        "    results_file.write(response.choices[0].message.content)\n",
        "    print(\"\\nResponse written to result/app.txt\\n\\n\")\n"
      ],
      "metadata": {
        "id": "t-DWkZ0ImvrZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function in the event loop\n",
        "await main()"
      ],
      "metadata": {
        "id": "tDoRyK1Am3In",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61daa0d2-f072-4b55-acb3-d2b121d823f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1: Add comments to my function\n",
            "2: Write unit tests for my function\n",
            "\"quit\" to exit the program\n",
            "\n",
            "Enter a number to select a task:1\n",
            "\n",
            "Enter a prompt: Add comments to my function\n",
            "\n",
            "Response written to result/app.txt\n",
            "\n",
            "\n",
            "\n",
            "1: Add comments to my function\n",
            "2: Write unit tests for my function\n",
            "\"quit\" to exit the program\n",
            "\n",
            "Enter a number to select a task:2\n",
            "\n",
            "Enter a prompt: Write unit tests for my function\n",
            "\n",
            "Response written to result/app.txt\n",
            "\n",
            "\n",
            "\n",
            "1: Add comments to my function\n",
            "2: Write unit tests for my function\n",
            "\"quit\" to exit the program\n",
            "\n",
            "Enter a number to select a task:q\n",
            "\n",
            "Enter a prompt: quit\n",
            "Invalid input. Please try again.\n",
            "\n",
            "1: Add comments to my function\n",
            "2: Write unit tests for my function\n",
            "\"quit\" to exit the program\n",
            "\n",
            "Enter a number to select a task:quit\n",
            "Exiting program...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJGBuL6Rrds9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}